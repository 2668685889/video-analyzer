#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é£ä¹¦æ•°æ®åŒæ­¥æœåŠ¡æ¨¡å—
è´Ÿè´£æœ¬åœ°æ•°æ®åº“ä¸é£ä¹¦å¤šç»´è¡¨æ ¼ä¹‹é—´çš„æ•°æ®åŒæ­¥
"""

import logging
import threading
import time
import json
from typing import Dict, List, Optional, Any
from datetime import datetime
import uuid

from ..api.feishu_client import FeishuClient
from .config import config
from .database import db
from .feishu_field_fixer import FeishuFieldFixer
from .custom_field_mapper import CustomFieldMapper
from .ai_output_adapter import AIOutputAdapter

class FeishuSyncService:
    """
    é£ä¹¦æ•°æ®åŒæ­¥æœåŠ¡ç±»
    æä¾›æœ¬åœ°æ•°æ®åº“ä¸é£ä¹¦å¤šç»´è¡¨æ ¼çš„åŒå‘åŒæ­¥åŠŸèƒ½
    """
    
    def __init__(self):
        """
        åˆå§‹åŒ–é£ä¹¦åŒæ­¥æœåŠ¡
        """
        self.feishu_client = None
        self.sync_lock = threading.Lock()
        self.logger = logging.getLogger(__name__)
        self.field_fixer = FeishuFieldFixer()
        self.custom_mapper = CustomFieldMapper()
        self.ai_adapter = AIOutputAdapter()
        self.last_sync_time = None
        self._init_client()
    
    def _init_client(self) -> bool:
        """
        åˆå§‹åŒ–é£ä¹¦å®¢æˆ·ç«¯
        
        Returns:
            bool: æ˜¯å¦åˆå§‹åŒ–æˆåŠŸ
        """
        try:
            if config.is_feishu_valid():
                feishu_config = config.get_feishu_config()
                self.feishu_client = FeishuClient(
                    app_id=feishu_config['app_id'],
                    app_secret=feishu_config['app_secret']
                )
                return True
            else:
                self.logger.debug("é£ä¹¦é…ç½®æ— æ•ˆï¼Œæ— æ³•åˆå§‹åŒ–å®¢æˆ·ç«¯")
                return False
        except Exception as e:
            self.logger.error(f"åˆå§‹åŒ–é£ä¹¦å®¢æˆ·ç«¯å¤±è´¥: {str(e)}")
            return False
    
    def test_connection(self) -> bool:
        """
        æµ‹è¯•é£ä¹¦è¿æ¥
        
        Returns:
            bool: è¿æ¥æ˜¯å¦æ­£å¸¸
        """
        if not self.feishu_client:
            return False
        return self.feishu_client.test_connection()
    
    def sync_record_to_feishu(self, sequence_id: str, force_resync: bool = False) -> bool:
        """
        å°†å•æ¡è®°å½•åŒæ­¥åˆ°é£ä¹¦
        
        Args:
            sequence_id (str): è®°å½•çš„åºåˆ—ID
            force_resync (bool): æ˜¯å¦å¼ºåˆ¶é‡æ–°åŒæ­¥å·²åŒæ­¥çš„è®°å½•
            
        Returns:
            bool: æ˜¯å¦åŒæ­¥æˆåŠŸ
        """
        if not self.feishu_client or not config.feishu_enabled:
            self.logger.warning(f"é£ä¹¦å®¢æˆ·ç«¯æœªåˆå§‹åŒ–æˆ–é£ä¹¦åŠŸèƒ½æœªå¯ç”¨: client={self.feishu_client is not None}, enabled={config.feishu_enabled}")
            return False
        
        try:
            with self.sync_lock:
                self.logger.info(f"å¼€å§‹åŒæ­¥è®°å½•åˆ°é£ä¹¦: sequence_id={sequence_id}")
                
                # ä»æœ¬åœ°æ•°æ®åº“è·å–è®°å½•
                record = db.get_analysis_by_sequence_id(sequence_id)
                if not record:
                    self.logger.error(f"æœªæ‰¾åˆ°åºåˆ—IDä¸º {sequence_id} çš„è®°å½•")
                    return False
                
                self.logger.info(f"è·å–åˆ°è®°å½•: æ–‡ä»¶å={record.get('file_name', 'Unknown')}, æ–‡ä»¶å¤§å°={record.get('file_size', 0)} bytes")
                
                # æ£€æŸ¥æ˜¯å¦å·²ç»åŒæ­¥è¿‡
                if record.get('feishu_record_id') and not force_resync:
                    self.logger.info(f"è®°å½• {sequence_id} å·²ç»åŒæ­¥åˆ°é£ä¹¦ï¼Œfeishu_record_id={record.get('feishu_record_id')}")
                    return True
                elif record.get('feishu_record_id') and force_resync:
                    self.logger.info(f"è®°å½• {sequence_id} å¼ºåˆ¶é‡æ–°åŒæ­¥ï¼Œæ¸…é™¤ç°æœ‰é£ä¹¦è®°å½•ID")
                    # æ¸…é™¤ç°æœ‰çš„é£ä¹¦è®°å½•IDï¼Œå¼ºåˆ¶åˆ›å»ºæ–°è®°å½•
                    db.update_feishu_record_id(sequence_id, None)
                
                self.logger.info("è®°å½•æœªåŒæ­¥ï¼Œå¼€å§‹å‡†å¤‡é£ä¹¦æ•°æ®...")
                
                # å‡†å¤‡é£ä¹¦è®°å½•æ•°æ®
                feishu_data = self._prepare_feishu_record(record)
                if not feishu_data:
                    self.logger.error(f"å‡†å¤‡é£ä¹¦æ•°æ®å¤±è´¥: {sequence_id}")
                    return False
                
                self.logger.info(f"é£ä¹¦æ•°æ®å‡†å¤‡å®Œæˆï¼Œå­—æ®µæ•°é‡: {len(feishu_data)}")
                self.logger.info(f"å‡†å¤‡å‘é€çš„é£ä¹¦æ•°æ®: {json.dumps(feishu_data, ensure_ascii=False, indent=2)}")
                
                # æ·»åŠ åˆ°é£ä¹¦è¡¨æ ¼
                feishu_config = config.get_feishu_config()
                self.logger.info(f"é£ä¹¦é…ç½®: app_token={feishu_config['app_token'][:10]}..., table_id={feishu_config['table_id']}")
                
                record_id = self.feishu_client.add_record(
                    app_token=feishu_config['app_token'],
                    table_id=feishu_config['table_id'],
                    record_data=feishu_data
                )
                
                if record_id:
                    # æ›´æ–°æœ¬åœ°è®°å½•çš„é£ä¹¦ID
                    self.logger.info(f"é£ä¹¦APIè¿”å›è®°å½•ID: {record_id}")
                    db.update_feishu_record_id(sequence_id, record_id)
                    # æ›´æ–°æœ€ååŒæ­¥æ—¶é—´
                    self.last_sync_time = datetime.now()
                    self.logger.info(f"è®°å½• {sequence_id} æˆåŠŸåŒæ­¥åˆ°é£ä¹¦ï¼Œè®°å½•ID: {record_id}")
                    return True
                else:
                    self.logger.error(f"è®°å½• {sequence_id} åŒæ­¥åˆ°é£ä¹¦å¤±è´¥ï¼Œæœªè¿”å›è®°å½•ID")
                    return False
                    
        except Exception as e:
            error_msg = str(e)
            if "FieldNameNotFound" in error_msg:
                self.logger.error(f"é£ä¹¦è¡¨æ ¼å­—æ®µä¸å­˜åœ¨é”™è¯¯: {error_msg}")
                self.logger.error("è§£å†³æ–¹æ¡ˆ:")
                self.logger.error("1. ç¡®ä¿é£ä¹¦åº”ç”¨å·²è¢«æ·»åŠ ä¸ºå¤šç»´è¡¨æ ¼åä½œè€…")
                self.logger.error("2. åœ¨åº”ç”¨ç¨‹åºä¸­ç‚¹å‡»'è®¾ç½®è¡¨æ ¼ç»“æ„'æŒ‰é’®")
                self.logger.error("3. æˆ–å‚è€ƒ shuoming/FEISHU_FIELD_SETUP_GUIDE.md æ‰‹åŠ¨åˆ›å»ºå­—æ®µ")
            else:
                self.logger.error(f"åŒæ­¥è®°å½•åˆ°é£ä¹¦å¼‚å¸¸: {error_msg}")
            return False
    
    def sync_all_records_to_feishu(self, include_synced: bool = False) -> Dict[str, int]:
        """
        å°†è®°å½•åŒæ­¥åˆ°é£ä¹¦
        
        Args:
            include_synced (bool): æ˜¯å¦åŒ…å«å·²åŒæ­¥çš„è®°å½•ï¼ˆæ‰§è¡Œæ›´æ–°æ“ä½œï¼‰
        
        Returns:
            Dict[str, int]: åŒæ­¥ç»“æœç»Ÿè®¡
        """
        if not self.feishu_client or not config.feishu_enabled:
            return {'success': 0, 'failed': 0, 'skipped': 0, 'created': 0, 'updated': 0}
        
        try:
            if include_synced:
                # è·å–æ‰€æœ‰è®°å½•
                all_records = db.get_all_history_records()
            else:
                # è·å–æ‰€æœ‰æœªåŒæ­¥çš„è®°å½•
                all_records = db.get_unsynced_records()
            
            success_count = 0
            failed_count = 0
            created_count = 0
            updated_count = 0
            
            for record in all_records:
                sequence_id = record['sequence_id']
                
                if record.get('feishu_record_id') and include_synced:
                    # å·²åŒæ­¥è®°å½•ï¼Œæ‰§è¡Œæ›´æ–°
                    if self.update_record_in_feishu(sequence_id):
                        success_count += 1
                        updated_count += 1
                    else:
                        failed_count += 1
                else:
                    # æœªåŒæ­¥è®°å½•ï¼Œæ‰§è¡Œæ–°å»º
                    if self.sync_record_to_feishu(sequence_id):
                        success_count += 1
                        created_count += 1
                    else:
                        failed_count += 1
                
                # æ·»åŠ å°å»¶è¿Ÿé¿å…APIé™æµ
                time.sleep(0.1)
            
            # æ›´æ–°æœ€ååŒæ­¥æ—¶é—´
            if success_count > 0:
                self.last_sync_time = datetime.now()
            
            self.logger.info(f"æ‰¹é‡åŒæ­¥å®Œæˆ: æˆåŠŸ {success_count} (æ–°å»º {created_count}, æ›´æ–° {updated_count}), å¤±è´¥ {failed_count}")
            return {
                'success': success_count,
                'failed': failed_count,
                'skipped': 0,
                'created': created_count,
                'updated': updated_count
            }
            
        except Exception as e:
            self.logger.error(f"æ‰¹é‡åŒæ­¥å¼‚å¸¸: {str(e)}")
            return {'success': 0, 'failed': 0, 'skipped': 0, 'created': 0, 'updated': 0}
    
    def update_record_in_feishu(self, sequence_id: str) -> bool:
        """
        æ›´æ–°é£ä¹¦ä¸­çš„è®°å½•
        
        Args:
            sequence_id (str): è®°å½•çš„åºåˆ—ID
            
        Returns:
            bool: æ˜¯å¦æ›´æ–°æˆåŠŸ
        """
        if not self.feishu_client or not config.feishu_enabled:
            return False
        
        try:
            with self.sync_lock:
                # ä»æœ¬åœ°æ•°æ®åº“è·å–è®°å½•
                record = db.get_analysis_by_sequence_id(sequence_id)
                if not record or not record.get('feishu_record_id'):
                    self.logger.error(f"è®°å½• {sequence_id} ä¸å­˜åœ¨æˆ–æœªåŒæ­¥åˆ°é£ä¹¦")
                    return False
                
                # å‡†å¤‡æ›´æ–°æ•°æ®
                feishu_data = self._prepare_feishu_record(record)
                
                # æ›´æ–°é£ä¹¦è®°å½•
                feishu_config = config.get_feishu_config()
                success = self.feishu_client.update_record(
                    app_token=feishu_config['app_token'],
                    table_id=feishu_config['table_id'],
                    record_id=record['feishu_record_id'],
                    record_data=feishu_data
                )
                
                if success:
                    self.logger.info(f"è®°å½• {sequence_id} åœ¨é£ä¹¦ä¸­æ›´æ–°æˆåŠŸ")
                    return True
                else:
                    # æ›´æ–°å¤±è´¥ï¼Œå¯èƒ½æ˜¯è®°å½•å·²è¢«åˆ é™¤ï¼Œå°è¯•é‡æ–°åˆ›å»º
                    self.logger.warning(f"è®°å½• {sequence_id} æ›´æ–°å¤±è´¥ï¼Œå¯èƒ½å·²è¢«åˆ é™¤ï¼Œå°è¯•é‡æ–°åˆ›å»º")
                    
                    # æ¸…é™¤æœ¬åœ°çš„é£ä¹¦è®°å½•ID
                    db.update_feishu_record_id(sequence_id, None)
                    
                    # ç›´æ¥åˆ›å»ºæ–°è®°å½•ï¼Œé¿å…sync_record_to_feishuçš„é‡å¤æ£€æŸ¥
                    return self._create_new_record(sequence_id)
                    
        except Exception as e:
            self.logger.error(f"æ›´æ–°é£ä¹¦è®°å½•å¼‚å¸¸: {str(e)}")
            # å¦‚æœæ˜¯ç½‘ç»œæˆ–å…¶ä»–å¼‚å¸¸ï¼Œä¹Ÿå°è¯•é‡æ–°åˆ›å»º
            try:
                self.logger.warning(f"æ›´æ–°å¼‚å¸¸ï¼Œå°è¯•æ¸…é™¤è®°å½•IDå¹¶é‡æ–°åˆ›å»º: {sequence_id}")
                db.update_feishu_record_id(sequence_id, None)
                return self._create_new_record(sequence_id)
            except Exception as retry_e:
                self.logger.error(f"é‡æ–°åˆ›å»ºè®°å½•ä¹Ÿå¤±è´¥: {str(retry_e)}")
                return False
    
    def _create_new_record(self, sequence_id: str) -> bool:
        """
        ç›´æ¥åˆ›å»ºæ–°çš„é£ä¹¦è®°å½•ï¼ˆä¸æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ï¼‰
        
        Args:
            sequence_id (str): è®°å½•çš„åºåˆ—ID
            
        Returns:
            bool: æ˜¯å¦åˆ›å»ºæˆåŠŸ
        """
        if not self.feishu_client or not config.feishu_enabled:
            return False
        
        try:
            # ä»æœ¬åœ°æ•°æ®åº“è·å–è®°å½•
            record = db.get_analysis_by_sequence_id(sequence_id)
            if not record:
                self.logger.error(f"æœªæ‰¾åˆ°åºåˆ—IDä¸º {sequence_id} çš„è®°å½•")
                return False
            
            self.logger.info(f"å¼€å§‹åˆ›å»ºæ–°çš„é£ä¹¦è®°å½•: sequence_id={sequence_id}")
            
            # å‡†å¤‡é£ä¹¦è®°å½•æ•°æ®
            feishu_data = self._prepare_feishu_record(record)
            if not feishu_data:
                self.logger.error(f"å‡†å¤‡é£ä¹¦æ•°æ®å¤±è´¥: {sequence_id}")
                return False
            
            # æ·»åŠ åˆ°é£ä¹¦è¡¨æ ¼
            feishu_config = config.get_feishu_config()
            record_id = self.feishu_client.add_record(
                app_token=feishu_config['app_token'],
                table_id=feishu_config['table_id'],
                record_data=feishu_data
            )
            
            if record_id:
                # æ›´æ–°æœ¬åœ°è®°å½•çš„é£ä¹¦ID
                self.logger.info(f"é£ä¹¦APIè¿”å›è®°å½•ID: {record_id}")
                db.update_feishu_record_id(sequence_id, record_id)
                # æ›´æ–°æœ€ååŒæ­¥æ—¶é—´
                self.last_sync_time = datetime.now()
                self.logger.info(f"è®°å½• {sequence_id} æˆåŠŸåˆ›å»ºåˆ°é£ä¹¦ï¼Œè®°å½•ID: {record_id}")
                return True
            else:
                self.logger.error(f"è®°å½• {sequence_id} åˆ›å»ºåˆ°é£ä¹¦å¤±è´¥ï¼Œæœªè¿”å›è®°å½•ID")
                return False
                
        except Exception as e:
            self.logger.error(f"åˆ›å»ºé£ä¹¦è®°å½•å¼‚å¸¸: {str(e)}")
            return False
    
    def delete_record_from_feishu(self, sequence_id: str) -> bool:
        """
        ä»é£ä¹¦ä¸­åˆ é™¤è®°å½•
        
        Args:
            sequence_id (str): è®°å½•çš„åºåˆ—ID
            
        Returns:
            bool: æ˜¯å¦åˆ é™¤æˆåŠŸ
        """
        if not self.feishu_client or not config.feishu_enabled:
            return False
        
        try:
            with self.sync_lock:
                # ä»æœ¬åœ°æ•°æ®åº“è·å–è®°å½•
                record = db.get_analysis_by_sequence_id(sequence_id)
                if not record or not record.get('feishu_record_id'):
                    self.logger.warning(f"è®°å½• {sequence_id} ä¸å­˜åœ¨æˆ–æœªåŒæ­¥åˆ°é£ä¹¦")
                    return True
                
                # ä»é£ä¹¦åˆ é™¤è®°å½•
                feishu_config = config.get_feishu_config()
                success = self.feishu_client.delete_record(
                    app_token=feishu_config['app_token'],
                    table_id=feishu_config['table_id'],
                    record_id=record['feishu_record_id']
                )
                
                if success:
                    # æ¸…é™¤æœ¬åœ°è®°å½•çš„é£ä¹¦ID
                    db.update_feishu_record_id(sequence_id, None)
                    self.logger.info(f"è®°å½• {sequence_id} ä»é£ä¹¦ä¸­åˆ é™¤æˆåŠŸ")
                    return True
                else:
                    self.logger.error(f"è®°å½• {sequence_id} ä»é£ä¹¦ä¸­åˆ é™¤å¤±è´¥")
                    return False
                    
        except Exception as e:
            self.logger.error(f"åˆ é™¤é£ä¹¦è®°å½•å¼‚å¸¸: {str(e)}")
            return False
    
    def _prepare_feishu_record(self, record: Dict) -> Dict[str, Any]:
        """
        å‡†å¤‡é£ä¹¦è®°å½•æ•°æ®
        ä¸¥æ ¼æŒ‰ç…§è‡ªå®šä¹‰å­—æ®µæ˜ å°„é…ç½®æ‰§è¡Œï¼ˆä¸ä½¿ç”¨å›é€€æœºåˆ¶ï¼‰
        
        Args:
            record (Dict): æœ¬åœ°æ•°æ®åº“è®°å½•
            
        Returns:
            Dict[str, Any]: é£ä¹¦è®°å½•æ•°æ®
        """
        try:
            # è§£æanalysis_resultä¸­çš„AIæ¨¡å‹è¿”å›æ•°æ®
            parsed_ai_data = self._parse_analysis_result(record.get('analysis_result', ''))
            
            # ä½¿ç”¨AIè¾“å‡ºæ ¼å¼é€‚é…å™¨å¤„ç†æ•°æ®
            adapter_result = self.ai_adapter.process_ai_output(parsed_ai_data)
            adapted_ai_data = adapter_result['output']
            
            # è®°å½•é€‚é…å™¨å¤„ç†ä¿¡æ¯
            validation_info = adapter_result['validation']
            processing_info = adapter_result['processing_info']
            self.logger.info(f"ğŸ¤– AIè¾“å‡ºé€‚é…å™¨å¤„ç†å®Œæˆ: æ ¼å¼={processing_info['format_type']}, æˆåŠŸç‡={validation_info['success_rate']:.2%}")
            self.logger.debug(f"ğŸ“Š æœ‰æ•ˆå­—æ®µ: {validation_info['valid_fields']}")
            if validation_info['empty_fields']:
                self.logger.debug(f"âš ï¸  ç©ºå­—æ®µ: {validation_info['empty_fields']}")
            
            # æ„å»ºå®Œæ•´çš„AIæ¨¡å‹æ•°æ®ç»“æ„ï¼ˆä½¿ç”¨ä¸­æ–‡å­—æ®µåï¼‰
            ai_model_data = {
                "è§†é¢‘åºåˆ—å·": record.get('sequence_id', ''),
                "è§†é¢‘æºè·¯å¾„": record.get('file_path', ''),
            }
            
            # åˆå¹¶è§£æå‡ºçš„AIåˆ†æç»“æœï¼ˆä¸è¦†ç›–é‡è¦çš„æ•°æ®åº“å­—æ®µï¼‰
            for key, value in adapted_ai_data.items():
                # ä¿æŠ¤é‡è¦çš„æ•°æ®åº“å­—æ®µä¸è¢«è¦†ç›–
                if key in ['è§†é¢‘åºåˆ—å·', 'è§†é¢‘æºè·¯å¾„'] and ai_model_data.get(key):
                    self.logger.debug(f"ğŸ›¡ï¸  ä¿æŠ¤å­—æ®µ '{key}' ä¸è¢«è¦†ç›–ï¼Œä¿æŒåŸå€¼: {ai_model_data[key]}")
                    continue
                ai_model_data[key] = value
            
            # ä¸¥æ ¼ä½¿ç”¨è‡ªå®šä¹‰å­—æ®µæ˜ å°„é…ç½®
            field_mappings = self.custom_mapper.get_field_mappings()
            if not field_mappings:
                error_msg = "âŒ æœªæ‰¾åˆ°è‡ªå®šä¹‰å­—æ®µæ˜ å°„é…ç½®ï¼Œæ— æ³•ç»§ç»­å¤„ç†"
                self.logger.error(error_msg)
                raise ValueError(error_msg)
            
            # ä½¿ç”¨è‡ªå®šä¹‰å­—æ®µæ˜ å°„å™¨è¿›è¡Œè½¬æ¢
            feishu_data = self.custom_mapper.transform_ai_data_to_feishu(ai_model_data)
            
            if not feishu_data:
                error_msg = "âŒ è‡ªå®šä¹‰å­—æ®µæ˜ å°„è½¬æ¢å¤±è´¥ï¼Œæœªäº§ç”Ÿæœ‰æ•ˆæ•°æ®"
                self.logger.error(error_msg)
                raise ValueError(error_msg)
            
            self.logger.info(f"âœ… ä¸¥æ ¼æŒ‰ç…§è‡ªå®šä¹‰å­—æ®µæ˜ å°„æˆåŠŸè½¬æ¢æ•°æ®")
            self.logger.info(f"ğŸ“‹ è½¬æ¢åçš„é£ä¹¦å­—æ®µ: {list(feishu_data.keys())}")
            
            # è®°å½•è¯¦ç»†çš„æ˜ å°„ä¿¡æ¯
            for ai_field, feishu_field in field_mappings.items():
                if ai_field in ai_model_data:
                    value = ai_model_data[ai_field]
                    self.logger.debug(f"ğŸ”„ å­—æ®µæ˜ å°„: {ai_field} -> {feishu_field} = {str(value)[:100]}{'...' if len(str(value)) > 100 else ''}")
            
            return feishu_data
            
        except Exception as e:
            self.logger.error(f"âŒ å‡†å¤‡é£ä¹¦è®°å½•æ•°æ®å¤±è´¥: {str(e)}")
            # è¿”å›æœ€å°åŒ–çš„å®‰å…¨æ•°æ®
            return self.field_fixer.create_minimal_test_record()
    
    def _parse_analysis_result(self, analysis_result: str) -> Dict[str, Any]:
        """
        è§£æanalysis_resultå­—æ®µä¸­çš„AIæ¨¡å‹è¿”å›æ•°æ®
        æ”¯æŒå¤šç§æ ¼å¼ï¼šJSONã€é”®å€¼å¯¹ã€Markdownç­‰
        
        Args:
            analysis_result (str): åˆ†æç»“æœå­—ç¬¦ä¸²
            
        Returns:
            Dict[str, Any]: è§£æåçš„æ•°æ®å­—å…¸
        """
        import json
        import re
        
        if not analysis_result or not analysis_result.strip():
            return {}
        
        try:
            # æ–¹æ³•1: å°è¯•ç›´æ¥è§£æJSON
            if analysis_result.strip().startswith('{') and analysis_result.strip().endswith('}'):
                parsed = json.loads(analysis_result)
                self.logger.debug("âœ… æˆåŠŸè§£æJSONæ ¼å¼çš„åˆ†æç»“æœ")
                return parsed
            
            # æ–¹æ³•2: æå–```jsonä»£ç å—ä¸­çš„JSON
            json_patterns = [
                r'```json\s*({.*?})\s*```',
                r'```\s*({.*?})\s*```',
                r'json\s*({.*?})'
            ]
            
            for pattern in json_patterns:
                json_match = re.search(pattern, analysis_result, re.DOTALL | re.IGNORECASE)
                if json_match:
                    try:
                        parsed = json.loads(json_match.group(1))
                        self.logger.debug(f"âœ… æˆåŠŸä»ä»£ç å—ä¸­è§£æJSON: {pattern}")
                        return parsed
                    except json.JSONDecodeError:
                        continue
            
            # æ–¹æ³•3: æŸ¥æ‰¾ä»»ä½•JSONå¯¹è±¡
            json_match = re.search(r'{[^{}]*(?:{[^{}]*}[^{}]*)*}', analysis_result, re.DOTALL)
            if json_match:
                try:
                    parsed = json.loads(json_match.group(0))
                    self.logger.debug("âœ… æˆåŠŸè§£æåµŒå…¥çš„JSONå¯¹è±¡")
                    return parsed
                except json.JSONDecodeError:
                    pass
            
            # æ–¹æ³•4: è§£æé”®å€¼å¯¹æ ¼å¼ï¼ˆæ”¯æŒå¤šç§åˆ†éš”ç¬¦ï¼‰
            result = {}
            lines = analysis_result.split('\n')
            
            # å¸¸è§çš„å­—æ®µåæ˜ å°„
            field_mappings = {
                'è§†é¢‘åºåˆ—å·': 'video_serial_number',
                'åºåˆ—å·': 'video_serial_number',
                'sequence_id': 'video_serial_number',
                'è§†é¢‘å†…å®¹æ‘˜è¦': 'video_content_summary',
                'å†…å®¹æ‘˜è¦': 'video_content_summary',
                'æ‘˜è¦': 'video_content_summary',
                'summary': 'video_content_summary',
                'è¯¦ç»†å†…å®¹æè¿°': 'detailed_content_description',
                'è¯¦ç»†æè¿°': 'detailed_content_description',
                'å†…å®¹æè¿°': 'detailed_content_description',
                'description': 'detailed_content_description',
                'ä¸»è¦äººç‰©å¯¹è±¡': 'main_characters_objects',
                'äººç‰©å¯¹è±¡': 'main_characters_objects',
                'ä¸»è¦äººç‰©': 'main_characters_objects',
                'characters': 'main_characters_objects',
                'å…³é”®è¯æ ‡ç­¾': 'keywords_tags',
                'å…³é”®è¯': 'keywords_tags',
                'æ ‡ç­¾': 'keywords_tags',
                'keywords': 'keywords_tags',
                'tags': 'keywords_tags',
                'è§†é¢‘æºè·¯å¾„': 'video_source_path',
                'æ–‡ä»¶è·¯å¾„': 'video_source_path',
                'è·¯å¾„': 'video_source_path',
                'path': 'video_source_path',
                'file_path': 'video_source_path'
            }
            
            for line in lines:
                line = line.strip()
                if not line:
                    continue
                
                # å°è¯•ä¸åŒçš„åˆ†éš”ç¬¦
                separators = [':', 'ï¼š', '=', '-', '|']
                for sep in separators:
                    if sep in line:
                        parts = line.split(sep, 1)
                        if len(parts) == 2:
                            key = parts[0].strip().strip('*').strip('#').strip()
                            value = parts[1].strip().strip('"').strip("'").strip()
                            
                            if key and value:
                                # å°è¯•æ˜ å°„åˆ°æ ‡å‡†å­—æ®µå
                                mapped_key = field_mappings.get(key.lower(), key)
                                if mapped_key not in result:  # é¿å…é‡å¤
                                    result[mapped_key] = value
                        break
            
            if result:
                self.logger.debug(f"âœ… æˆåŠŸè§£æé”®å€¼å¯¹æ ¼å¼ï¼Œæå–åˆ° {len(result)} ä¸ªå­—æ®µ")
                return result
            
            # æ–¹æ³•5: å°è¯•ä»è‡ªç„¶è¯­è¨€ä¸­æå–ä¿¡æ¯
            self.logger.warning("âš ï¸  æ— æ³•è§£æç»“æ„åŒ–æ•°æ®ï¼Œå°è¯•ä»æ–‡æœ¬ä¸­æå–ä¿¡æ¯")
            
            # ç®€å•çš„æ–‡æœ¬æå–é€»è¾‘
            text_result = {
                'video_content_summary': analysis_result[:500] if len(analysis_result) > 500 else analysis_result,
                'detailed_content_description': analysis_result
            }
            
            return text_result
            
        except Exception as e:
            self.logger.error(f"âŒ è§£æanalysis_resultå¼‚å¸¸: {str(e)}")
            # è¿”å›åŸå§‹æ–‡æœ¬ä½œä¸ºæ‘˜è¦
            return {
                'video_content_summary': analysis_result[:200] if analysis_result else '',
                'detailed_content_description': analysis_result if analysis_result else ''
            }
    
    def _analyze_and_adapt_ai_data(self, ai_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        ä¸¥æ ¼æŒ‰ç…§è‡ªå®šä¹‰æ˜ å°„é…ç½®è¿›è¡Œå­—æ®µæ˜ å°„ï¼ˆä¸ä½¿ç”¨æ™ºèƒ½ç®—æ³•ï¼‰
        
        Args:
            ai_data (Dict[str, Any]): AIæ¨¡å‹è¿”å›çš„åŸå§‹æ•°æ®
            
        Returns:
            Dict[str, Any]: ä¸¥æ ¼æŒ‰é…ç½®æ˜ å°„åçš„æ•°æ®
        """
        try:
            # è·å–å½“å‰çš„å­—æ®µæ˜ å°„é…ç½®
            ai_model_fields = self.custom_mapper.get_ai_model_fields()
            field_mappings = self.custom_mapper.get_field_mappings()
            
            if not ai_model_fields or not field_mappings:
                self.logger.debug("ğŸ“‹ æœªæ‰¾åˆ°å­—æ®µæ˜ å°„é…ç½®ï¼Œè¿”å›åŸå§‹æ•°æ®")
                return ai_data
            
            adapted_data = {}
            unmapped_fields = []
            
            # ä¸¥æ ¼æŒ‰ç…§é…ç½®è¿›è¡Œå­—æ®µæ˜ å°„ï¼ˆä»…ç²¾ç¡®åŒ¹é…ï¼‰
            for key, value in ai_data.items():
                # åªè¿›è¡Œç²¾ç¡®åŒ¹é…ï¼Œä¸ä½¿ç”¨æ™ºèƒ½ç®—æ³•
                if key in field_mappings:
                    adapted_data[key] = value
                    self.logger.debug(f"âœ… ç²¾ç¡®åŒ¹é…: {key} -> {field_mappings[key]}")
                else:
                    unmapped_fields.append(key)
                    self.logger.debug(f"âš ï¸  å­—æ®µ '{key}' æœªåœ¨æ˜ å°„é…ç½®ä¸­æ‰¾åˆ°ï¼Œè·³è¿‡")
            
            if unmapped_fields:
                self.logger.warning(f"âš ï¸  ä»¥ä¸‹å­—æ®µæœªåœ¨æ˜ å°„é…ç½®ä¸­å®šä¹‰ï¼Œå·²è·³è¿‡: {unmapped_fields}")
            
            # ç¡®ä¿é…ç½®ä¸­å®šä¹‰çš„AIå­—æ®µéƒ½å­˜åœ¨ï¼ˆä½¿ç”¨é»˜è®¤å€¼ï¼Œä½†ä¸è¦†ç›–å·²æœ‰å€¼ï¼‰
            for ai_field in ai_model_fields.keys():
                if ai_field not in adapted_data:
                    adapted_data[ai_field] = ''
                    self.logger.debug(f"ğŸ”§ ä¸ºé…ç½®å­—æ®µ '{ai_field}' è®¾ç½®é»˜è®¤å€¼")
            
            self.logger.info(f"âœ… ä¸¥æ ¼æ˜ å°„å®Œæˆï¼ŒæˆåŠŸæ˜ å°„å­—æ®µæ•°: {len([k for k in ai_data.keys() if k in field_mappings])}")
            return adapted_data
            
        except Exception as e:
            self.logger.error(f"âŒ ä¸¥æ ¼æ˜ å°„å¤±è´¥: {str(e)}")
            return ai_data
    
    def _generate_tags(self, record: Dict) -> str:
        """
        åŸºäºè®°å½•å†…å®¹ç”Ÿæˆæ ‡ç­¾
        
        Args:
            record (Dict): æ•°æ®åº“è®°å½•
            
        Returns:
            str: é€—å·åˆ†éš”çš„æ ‡ç­¾å­—ç¬¦ä¸²
        """
        tags = []
        
        # åŸºäºæ–‡ä»¶æ ¼å¼æ·»åŠ æ ‡ç­¾
        if record.get('mime_type'):
            file_format = record['mime_type'].split('/')[-1]
            tags.append(f"æ ¼å¼:{file_format}")
        
        # åŸºäºæ–‡ä»¶å¤§å°æ·»åŠ æ ‡ç­¾
        file_size = record.get('file_size', 0)
        if file_size > 100 * 1024 * 1024:  # å¤§äº100MB
            tags.append("å¤§æ–‡ä»¶")
        elif file_size < 10 * 1024 * 1024:  # å°äº10MB
            tags.append("å°æ–‡ä»¶")
        
        # åŸºäºåˆ†ææç¤ºè¯æ·»åŠ æ ‡ç­¾
        prompt = record.get('analysis_prompt', '').lower()
        if 'æ‘˜è¦' in prompt:
            tags.append("æ‘˜è¦åˆ†æ")
        if 'åˆ†ç±»' in prompt:
            tags.append("å†…å®¹åˆ†ç±»")
        if 'æƒ…æ„Ÿ' in prompt:
            tags.append("æƒ…æ„Ÿåˆ†æ")
        if 'å…³é”®è¯' in prompt:
            tags.append("å…³é”®è¯æå–")
        
        # æ·»åŠ æ—¶é—´æ ‡ç­¾
        created_at = record.get('created_at')
        if created_at:
            try:
                dt = datetime.fromisoformat(created_at.replace('Z', '+00:00'))
                tags.append(f"æ—¥æœŸ:{dt.strftime('%Y-%m')}")
            except:
                pass
        
        return ",".join(tags)
    
    def _format_datetime(self, datetime_str: str) -> int:
        """
        æ ¼å¼åŒ–æ—¥æœŸæ—¶é—´ä¸ºé£ä¹¦æ—¶é—´æˆ³
        
        Args:
            datetime_str (str): æ—¥æœŸæ—¶é—´å­—ç¬¦ä¸²
            
        Returns:
            int: æ—¶é—´æˆ³ï¼ˆæ¯«ç§’ï¼‰
        """
        try:
            if datetime_str:
                dt = datetime.fromisoformat(datetime_str.replace('Z', '+00:00'))
                return int(dt.timestamp() * 1000)
            return int(datetime.now().timestamp() * 1000)
        except:
            return int(datetime.now().timestamp() * 1000)
    
    def setup_feishu_table(self) -> bool:
        """
        è®¾ç½®é£ä¹¦è¡¨æ ¼ï¼ˆåˆ›å»ºè¡¨æ ¼å’Œå­—æ®µï¼‰
        
        Returns:
            bool: æ˜¯å¦è®¾ç½®æˆåŠŸ
        """
        if not self.feishu_client:
            return False
        
        try:
            feishu_config = config.get_feishu_config()
            
            # å¦‚æœå·²æœ‰è¡¨æ ¼é…ç½®ï¼ŒéªŒè¯æ˜¯å¦çœŸå®å­˜åœ¨
            if feishu_config['app_token'] and feishu_config['table_id']:
                if self.feishu_client.verify_table_exists(feishu_config['app_token'], feishu_config['table_id']):
                    self.logger.info("é£ä¹¦è¡¨æ ¼å·²é…ç½®ä¸”å­˜åœ¨")
                    return True
                else:
                    self.logger.warning("é…ç½®çš„é£ä¹¦è¡¨æ ¼ä¸å­˜åœ¨ï¼Œå°†é‡æ–°åˆ›å»º")
                    # æ¸…ç©ºæ— æ•ˆé…ç½®
                    config.update_feishu_config({'app_token': '', 'table_id': ''})
                    feishu_config['app_token'] = ''
                    feishu_config['table_id'] = ''
            
            # åˆ›å»ºå¤šç»´è¡¨æ ¼
            if not feishu_config['app_token']:
                app_token = self.feishu_client.create_bitable("è§†é¢‘åˆ†æç»“æœ")
                if not app_token:
                    self.logger.error("åˆ›å»ºé£ä¹¦å¤šç»´è¡¨æ ¼å¤±è´¥")
                    return False
                
                # æ›´æ–°é…ç½®
                config.update_feishu_config({'app_token': app_token})
                feishu_config['app_token'] = app_token
            
            # åˆ›å»ºæ•°æ®è¡¨
            if not feishu_config['table_id']:
                table_id = self.feishu_client.create_table(
                    app_token=feishu_config['app_token'],
                    table_name="è§†é¢‘åˆ†ææ•°æ®"
                )
                if not table_id:
                    self.logger.error("åˆ›å»ºé£ä¹¦æ•°æ®è¡¨å¤±è´¥")
                    return False
                
                # åˆ›å»ºå­—æ®µ
                fields = self.feishu_client.get_video_analysis_fields()
                if not self.feishu_client.create_fields(
                    app_token=feishu_config['app_token'],
                    table_id=table_id,
                    fields=fields
                ):
                    self.logger.error("åˆ›å»ºé£ä¹¦è¡¨æ ¼å­—æ®µå¤±è´¥")
                    return False
                
                # æ›´æ–°é…ç½®
                config.update_feishu_config({'table_id': table_id})
            
            self.logger.info("é£ä¹¦è¡¨æ ¼è®¾ç½®å®Œæˆ")
            return True
            
        except Exception as e:
            self.logger.error(f"è®¾ç½®é£ä¹¦è¡¨æ ¼å¼‚å¸¸: {str(e)}")
            return False
    
    def get_sync_status(self) -> Dict[str, Any]:
        """
        è·å–åŒæ­¥çŠ¶æ€ä¿¡æ¯
        
        Returns:
            Dict[str, Any]: åŒæ­¥çŠ¶æ€ä¿¡æ¯
        """
        try:
            total_records = db.get_total_analysis_count()
            synced_records = db.get_synced_records_count()
            unsynced_records = total_records - synced_records
            
            return {
                'enabled': config.feishu_enabled,
                'connected': self.test_connection(),
                'total_records': total_records,
                'synced_records': synced_records,
                'unsynced_records': unsynced_records,
                'sync_rate': (synced_records / total_records * 100) if total_records > 0 else 0,
                'last_sync_time': self.last_sync_time.isoformat() if self.last_sync_time else None
            }
        except Exception as e:
            self.logger.error(f"è·å–åŒæ­¥çŠ¶æ€å¼‚å¸¸: {str(e)}")
            return {
                'enabled': False,
                'connected': False,
                'total_records': 0,
                'synced_records': 0,
                'unsynced_records': 0,
                'sync_rate': 0,
                'last_sync_time': None
            }

# åˆ›å»ºå…¨å±€åŒæ­¥æœåŠ¡å®ä¾‹
feishu_sync = FeishuSyncService()